{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LHpev1bn1ZxC"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"transformers==4.31.0\" \"datasets==2.13.0\" \"accelerate==0.21.0\" \"trl==0.4.7\" \"safetensors>=0.3.1\" --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPTNeoForCausalLM, AutoTokenizer,OPTForCausalLM, AutoModel"
      ],
      "metadata": {
        "id": "zE27MgK41inC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\", bos_token='<|startoftext|>',\n",
        "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KbaLtje1i_g",
        "outputId": "6b6a3aa4-cde2-4b97-90d9-ef2ec0fbeea4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/instruct_data_chatgpt_generate.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mFJ_98K-1jCh",
        "outputId": "6edb6172-46b3-4fb9-d2f6-cc7452a6d3bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Instruction  \\\n",
              "0  Use the Input and generate the suitable catego...   \n",
              "1  Use the Input and generate the suitable catego...   \n",
              "2  Use the Input and generate the suitable catego...   \n",
              "3  Use the Input and generate the suitable catego...   \n",
              "4  Use the Input and generate the suitable catego...   \n",
              "\n",
              "                             Context               Response  \\\n",
              "0  Lions, Tigers, Cheetahs, Leopards               Big Cats   \n",
              "1     Piano, Guitar, Violin, Trumpet    Musical Instruments   \n",
              "2      Apple, Banana, Cherry, Orange                 Fruits   \n",
              "3           Toyota, Ford, BMW, Tesla             Car Brands   \n",
              "4            Python, Java, C++, Ruby  Programming Languages   \n",
              "\n",
              "              Category  \n",
              "0  category_generation  \n",
              "1  category_generation  \n",
              "2  category_generation  \n",
              "3  category_generation  \n",
              "4  category_generation  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7fd21b0-50a8-4ac4-b524-34fc4255b06c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Instruction</th>\n",
              "      <th>Context</th>\n",
              "      <th>Response</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Use the Input and generate the suitable catego...</td>\n",
              "      <td>Lions, Tigers, Cheetahs, Leopards</td>\n",
              "      <td>Big Cats</td>\n",
              "      <td>category_generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Use the Input and generate the suitable catego...</td>\n",
              "      <td>Piano, Guitar, Violin, Trumpet</td>\n",
              "      <td>Musical Instruments</td>\n",
              "      <td>category_generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Use the Input and generate the suitable catego...</td>\n",
              "      <td>Apple, Banana, Cherry, Orange</td>\n",
              "      <td>Fruits</td>\n",
              "      <td>category_generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Use the Input and generate the suitable catego...</td>\n",
              "      <td>Toyota, Ford, BMW, Tesla</td>\n",
              "      <td>Car Brands</td>\n",
              "      <td>category_generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Use the Input and generate the suitable catego...</td>\n",
              "      <td>Python, Java, C++, Ruby</td>\n",
              "      <td>Programming Languages</td>\n",
              "      <td>category_generation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7fd21b0-50a8-4ac4-b524-34fc4255b06c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7fd21b0-50a8-4ac4-b524-34fc4255b06c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7fd21b0-50a8-4ac4-b524-34fc4255b06c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d178602-b535-457c-87f9-a0f217ae110a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d178602-b535-457c-87f9-a0f217ae110a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d178602-b535-457c-87f9-a0f217ae110a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_df = df[df['Category']=='category_generation']"
      ],
      "metadata": {
        "id": "VyPFNw1x_on7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cat_df.iterrows():\n",
        "  text = f\"\"\" <|startoftext|>\\n### Instruction:\\n{i[1]['Instruction']}\\n\\nInput:\\n{i[1]['Context']}\\n\\n### Response:\\n{i[1]['Response']}\\n<|endoftext|>\"\"\"\n",
        "  print(text)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8gjfUw44bDl",
        "outputId": "5727f3c0-451e-44be-fb69-986e2f84a8c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " <|startoftext|>\n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "Lions, Tigers, Cheetahs, Leopards\n",
            "\n",
            "### Response:\n",
            "Big Cats\n",
            "<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InstructDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "\n",
        "        for i in cat_df.iterrows():\n",
        "            text = f\"\"\" <|startoftext|>\\n### Instruction:\\n{i[1]['Instruction']}\\n\\nInput:\\n{i[1]['Context']}\\n\\n### Response:\\n{i[1]['Response']}\\n<|endoftext|>\"\"\"\n",
        "            encodings_dict = tokenizer(text,\n",
        "                                       truncation=True,\n",
        "                                       max_length=max_length,\n",
        "                                       padding=\"max_length\"\n",
        "                                       )\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "metadata": {
        "id": "tlparNh61jLj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128"
      ],
      "metadata": {
        "id": "8-apN6_Z5zdS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = InstructDataset(df, tokenizer, max_length=max_length)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
      ],
      "metadata": {
        "id": "Q7-Y4XrK1jOw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "                                  output_dir='./results',\n",
        "                                  num_train_epochs=15,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=4,\n",
        "                                  warmup_steps=10,\n",
        "                                  logging_steps = 10,\n",
        "                                  weight_decay=0.1,\n",
        "                                  logging_dir='./logs'\n",
        "                                  )"
      ],
      "metadata": {
        "id": "6lMWrRVp5uUg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Trainer(model=model, args=training_args, train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
        "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
        "                                                              'labels': torch.stack([f[0] for f in data])}).train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "j45vvZWS5uXj",
        "outputId": "068d9a27-f0ff-4b7b-b872-00d6fd3162f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 00:25, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.082000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.079900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.030900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=0.5572239051262537, metrics={'train_runtime': 25.6832, 'train_samples_per_second': 10.513, 'train_steps_per_second': 2.92, 'total_flos': 250585263636480.0, 'train_loss': 0.5572239051262537, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        " <|startoftext|>\n",
        "### Instruction:\n",
        "Use the Input and generate the suitable category name\n",
        "\n",
        "Input:\n",
        "google chrome, mozila firebox, safari\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to('cuda')\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,\n",
        "                                top_k=40,\n",
        "                                max_length = 300,\n",
        "                                top_p=0.9,\n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "  print(\"===============================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlOEJvj_5uaE",
        "outputId": "aa36a423-8702-4ab0-8b03-615b62d4c7f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  198,   220, 50257,   198, 21017, 46486,    25,   198, 11041,   262,\n",
            "         23412,   290,  7716,   262, 11080,  6536,  1438,   198,   198, 20560,\n",
            "            25,   198, 13297, 32030,    11,  6941,    89, 10102,  2046,  3524,\n",
            "            11,  1932,  2743,   198,   198, 21017, 18261,    25,   198]],\n",
            "       device='cuda:0')\n",
            "0: \n",
            " \n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "google chrome, mozila firebox, safari\n",
            "\n",
            "### Response:\n",
            "Android, iOS, Windows, Linux\n",
            "\n",
            "\n",
            "===============================\n",
            "1: \n",
            " \n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "google chrome, mozila firebox, safari\n",
            "\n",
            "### Response:\n",
            "Android, Windows, Linux\n",
            "\n",
            "\n",
            "===============================\n",
            "2: \n",
            " \n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "google chrome, mozila firebox, safari\n",
            "\n",
            "### Response:\n",
            "Operating Systems\n",
            "\n",
            "\n",
            "===============================\n",
            "3: \n",
            " \n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "google chrome, mozila firebox, safari\n",
            "\n",
            "### Response:\n",
            "Big Brands\n",
            "\n",
            "\n",
            "===============================\n",
            "4: \n",
            " \n",
            "### Instruction:\n",
            "Use the Input and generate the suitable category name\n",
            "\n",
            "Input:\n",
            "google chrome, mozila firebox, safari\n",
            "\n",
            "### Response:\n",
            "My Brands\n",
            "\n",
            "\n",
            "===============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ytNXAOl1jRx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adUGnUkD1jVS"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}